#!/usr/bin/env python3
"""
ImageBot ‚Äî —á–∞—Ç-–±–æ—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ OpenAI GPT Image.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Telegram –∏ CLI-—Ä–µ–∂–∏–º.
"""

import asyncio
import logging
import os
import sys
from pathlib import Path

from dotenv import load_dotenv

from processor import ImageProcessor

load_dotenv()

# ANSI-—Ü–≤–µ—Ç–∞ –¥–ª—è —É—Ä–æ–≤–Ω–µ–π –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
_COLORS = {
    logging.DEBUG: "\033[36m",    # cyan
    logging.INFO: "\033[32m",    # green
    logging.WARNING: "\033[33m", # yellow
    logging.ERROR: "\033[31m",   # red
    logging.CRITICAL: "\033[35m\033[1m",  # bold magenta
}
_RESET = "\033[0m"


class ColoredFormatter(logging.Formatter):
    """–§–æ—Ä–º–∞—Ç—Ç–µ—Ä —Å –≤—ã–¥–µ–ª–µ–Ω–∏–µ–º —É—Ä–æ–≤–Ω–µ–π —Ü–≤–µ—Ç–æ–º (—Ç–æ–ª—å–∫–æ –¥–ª—è TTY)."""

    def format(self, record: logging.LogRecord) -> str:
        msg = super().format(record)
        if sys.stderr.isatty() and record.levelno in _COLORS:
            color = _COLORS[record.levelno]
            levelname = record.levelname
            spaces = 8 - len(levelname)  # padding –∏–∑ %(levelname)-8s
            old = f"| {levelname}{' ' * spaces}"
            new = f"| {color}{levelname}{_RESET}{' ' * spaces}"
            msg = msg.replace(old, new, 1)
        return msg


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
# –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ª–æ–≥–∏ –≤ –∫–æ–Ω—Å–æ–ª—å –æ—Ç–∫–ª—é—á–µ–Ω—ã (–¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∫–∞–∫ —Å–µ—Ä–≤–∏—Å).
# –§–ª–∞–≥ --log –∏–ª–∏ -v –≤–∫–ª—é—á–∞–µ—Ç –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å.
_LOG_CONSOLE = "--log" in sys.argv or "-v" in sys.argv
if "--log" in sys.argv:
    sys.argv.remove("--log")
if "-v" in sys.argv:
    sys.argv.remove("-v")

LOG_LEVEL = os.environ.get("LOG_LEVEL", "INFO").upper()
LOG_FORMAT = "%(asctime)s | %(levelname)-8s | %(name)s | %(message)s"
LOG_DATEFMT = "%Y-%m-%d %H:%M:%S"

root = logging.getLogger()
root.handlers.clear()
root.setLevel(getattr(logging, LOG_LEVEL, logging.INFO))
if _LOG_CONSOLE:
    _handler = logging.StreamHandler(sys.stderr)
    _handler.setFormatter(ColoredFormatter(LOG_FORMAT, datefmt=LOG_DATEFMT))
    root.addHandler(_handler)
else:
    root.addHandler(logging.NullHandler())

logger = logging.getLogger(__name__)
# –°–Ω–∏–∂–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–æ–≤ python-telegram-bot
logging.getLogger("telegram").setLevel(logging.WARNING)


def run_telegram_bot():
    """–ó–∞–ø—É—Å–∫ Telegram-–±–æ—Ç–∞."""
    logger.info("–ó–∞–ø—É—Å–∫ Telegram-–±–æ—Ç–∞...")

    try:
        from telegram import Update
        from telegram.ext import (
            Application,
            CommandHandler,
            ContextTypes,
            MessageHandler,
            filters,
            PicklePersistence,
        )
    except ImportError:
        logger.error("–ú–æ–¥—É–ª—å python-telegram-bot –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print(
            "–î–ª—è Telegram-—Ä–µ–∂–∏–º–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install python-telegram-bot"
        )
        sys.exit(1)

    token = os.environ.get("TELEGRAM_BOT_TOKEN")
    if not token:
        logger.error("TELEGRAM_BOT_TOKEN –Ω–µ –∑–∞–¥–∞–Ω")
        print(
            "–ó–∞–¥–∞–π—Ç–µ TELEGRAM_BOT_TOKEN –≤ .env (—Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –∏–∑ .env.example)"
        )
        sys.exit(1)

    logger.info("–¢–æ–∫–µ–Ω –∑–∞–≥—Ä—É–∂–µ–Ω, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    processor = ImageProcessor()

    DEFAULT_MODEL = "gpt-image-1.5"
    MODELS = {
        "gpt-5.2": "gpt-5.2",
        "gpt-image-1": "gpt-image-1",
        "gpt-image-1.5": "gpt-image-1.5",
        "dall-e-2": "dall-e-2",
        "create": "create",  # text-to-image, gpt-image-1.5
        "dalle_create": "dalle_create",  # text-to-image, DALL-E 2
    }

    def set_model(context: ContextTypes.DEFAULT_TYPE, model: str) -> str:
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–º—è –º–æ–¥–µ–ª–∏."""
        context.user_data["model"] = model
        return model

    def get_model(context: ContextTypes.DEFAULT_TYPE) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        return context.user_data.get("model", DEFAULT_MODEL)

    async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
        user = update.effective_user
        logger.info("–ö–æ–º–∞–Ω–¥–∞ /start –æ—Ç user_id=%s, username=%s", user.id, user.username)
        set_model(context, "gpt-5.2")
        await update.message.reply_text(
            "üñº ImageBot\n\n"
            "–ú–æ–¥–µ–ª—å: gpt-5.2 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)\n\n"
            "–†–µ–∂–∏–º—ã: —á–∞—Ç —Ç–µ–∫—Å—Ç–æ–º (/text), —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ (/image1, /image15, /dalle), –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ —Ç–µ–∫—Å—Ç—É (/create).\n\n"
            "–ö–æ–º–∞–Ω–¥—ã:\n"
            "/help ‚Äî —Å–ø—Ä–∞–≤–∫–∞ –ø–æ –≤—Å–µ–º –∫–æ–º–∞–Ω–¥–∞–º\n"
            "/text ‚Äî —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º (gpt-5.2), 1 —Ñ–æ—Ç–æ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è\n"
            "/image1 ‚Äî gpt-image-1\n"
            "/image15 ‚Äî gpt-image-1.5\n"
            "/dalle ‚Äî DALL-E 2 (—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ 1 —Ñ–æ—Ç–æ)\n"
            "/create ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ —Ç–µ–∫—Å—Ç—É (gpt-image-1.5)\n"
            "/dalle_gen ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ —Ç–µ–∫—Å—Ç—É (DALL-E 2)"
        )

    MODEL_LABELS = {
        "gpt-image-1": "gpt-image-1",
        "gpt-image-1.5": "gpt-image-1.5",
        "dall-e-2": "DALL-E 2",
        "create": "gpt-image-1.5 (create)",
        "dalle_create": "DALL-E 2 (create)",
    }

    def _format_image_error(exc: Exception) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—à–∏–±–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        code = None
        if hasattr(exc, "body") and isinstance(exc.body, dict):
            err = exc.body.get("error") or exc.body
            code = err.get("code") if isinstance(err, dict) else None
        if hasattr(exc, "code"):
            code = code or getattr(exc, "code", None)
        if not code and "moderation_blocked" in str(exc):
            code = "moderation_blocked"
        if code == "moderation_blocked":
            return (
                "‚ö†Ô∏è –ó–∞–ø—Ä–æ—Å –æ—Ç–∫–ª–æ–Ω—ë–Ω —Å–∏—Å—Ç–µ–º–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ OpenAI.\n\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ. "
                "–ï—Å–ª–∏ —Å—á–∏—Ç–∞–µ—Ç–µ —ç—Ç–æ –æ—à–∏–±–∫–æ–π ‚Äî –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ support: help.openai.com"
            )
        return str(exc)

    async def cmd_image1(update: Update, context: ContextTypes.DEFAULT_TYPE):
        set_model(context, "gpt-image-1")
        await update.message.reply_text(
            "‚úÖ –ú–æ–¥–µ–ª—å: gpt-image-1 (—Ä–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω)\n\n"
            "–ú–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å 1‚Äì10 —Ñ–æ—Ç–æ (–∞–ª—å–±–æ–º–æ–º –∏–ª–∏ –ø–æ –æ–¥–Ω–æ–º—É). "
            "–§–æ—Ç–æ –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏."
        )

    async def cmd_image15(update: Update, context: ContextTypes.DEFAULT_TYPE):
        set_model(context, "gpt-image-1.5")
        await update.message.reply_text(
            "‚úÖ –ú–æ–¥–µ–ª—å: gpt-image-1.5 (—Ä–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω)\n\n"
            "–ú–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å 1‚Äì10 —Ñ–æ—Ç–æ (–∞–ª—å–±–æ–º–æ–º –∏–ª–∏ –ø–æ –æ–¥–Ω–æ–º—É). "
            "–§–æ—Ç–æ –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏."
        )

    async def cmd_dalle(update: Update, context: ContextTypes.DEFAULT_TYPE):
        set_model(context, "dall-e-2")
        await update.message.reply_text(
            "‚úÖ –ú–æ–¥–µ–ª—å: DALL-E 2 (—Ä–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω)\n\n"
            "‚ö†Ô∏è DALL-E 2 –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ 1 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
        )

    async def cmd_create(update: Update, context: ContextTypes.DEFAULT_TYPE):
        set_model(context, "create")
        await update.message.reply_text(
            "‚úÖ –†–µ–∂–∏–º: Create (—Ä–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω)\n\n"
            "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ —Ç–µ–∫—Å—Ç—É –±–µ–∑ —Ñ–æ—Ç–æ. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ ‚Äî –ø–æ–ª—É—á–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.\n"
            "–ú–æ–¥–µ–ª—å: gpt-image-1.5"
        )

    async def cmd_dalle_gen(update: Update, context: ContextTypes.DEFAULT_TYPE):
        set_model(context, "dalle_create")
        await update.message.reply_text(
            "‚úÖ –†–µ–∂–∏–º: DALL-E 2 Gen (—Ä–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω)\n\n"
            "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ —Ç–µ–∫—Å—Ç—É –±–µ–∑ —Ñ–æ—Ç–æ. –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ ‚Äî –ø–æ–ª—É—á–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.\n"
            "–ú–æ–¥–µ–ª—å: DALL-E 2 (–¥–æ 1000 —Å–∏–º–≤–æ–ª–æ–≤)"
        )

    TELEGRAM_MAX_MESSAGE = 4000  # –ª–∏–º–∏—Ç Telegram 4096, 4000 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

    async def cmd_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
        set_model(context, "gpt-5.2")
        await update.message.reply_text(
            "‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º (gpt-5.2)\n\n"
            "–ß–∞—Ç —Å OpenAI —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–º (–±–µ–∑ —Ñ–æ—Ç–æ) –∏–ª–∏ –∞–Ω–∞–ª–∏–∑ 1 —Ñ–æ—Ç–æ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–æ–º–∞–Ω–¥–µ.\n"
            "–î–ª–∏–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã (>4000 —Å–∏–º–≤–æ–ª–æ–≤) —Ä–∞–∑–±–∏–≤–∞—é—Ç—Å—è –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π."
        )

    async def cmd_help(update: Update, context: ContextTypes.DEFAULT_TYPE):
        await update.message.reply_text(
            "üìñ ImageBot ‚Äî –°–ø—Ä–∞–≤–∫–∞ –ø–æ –∫–æ–º–∞–Ω–¥–∞–º\n\n"
            "/start ‚Äî –ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ä–µ–∂–∏–º gpt-5.2 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.\n\n"
            "/text ‚Äî –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º (gpt-5.2). –ß–∞—Ç —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –∞–Ω–∞–ª–∏–∑ 1 —Ñ–æ—Ç–æ. –î–ª–∏–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã —Ä–∞–∑–±–∏–≤–∞—é—Ç—Å—è –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π.\n\n"
            "/image1 ‚Äî –ú–æ–¥–µ–ª—å gpt-image-1. –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ 1‚Äì10 —Ñ–æ—Ç–æ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–æ–º–∞–Ω–¥–µ.\n\n"
            "/image15 ‚Äî –ú–æ–¥–µ–ª—å gpt-image-1.5. –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ 1‚Äì10 —Ñ–æ—Ç–æ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–æ–º–∞–Ω–¥–µ.\n\n"
            "/dalle ‚Äî DALL-E 2. –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ 1 —Ñ–æ—Ç–æ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–æ–º–∞–Ω–¥–µ.\n\n"
            "/create ‚Äî –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ —Ç–µ–∫—Å—Ç—É –±–µ–∑ —Ñ–æ—Ç–æ (gpt-image-1.5).\n\n"
            "/dalle_gen ‚Äî –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ —Ç–µ–∫—Å—Ç—É –±–µ–∑ —Ñ–æ—Ç–æ (DALL-E 2, –¥–æ 1000 —Å–∏–º–≤–æ–ª–æ–≤)."
        )

    MEDIA_GROUP_DELAY = 2  # —Å–µ–∫ ‚Äî –∂–¥—ë–º –≤—Å–µ —Ñ–æ—Ç–æ –∞–ª—å–±–æ–º–∞
    media_groups: dict[str, dict] = {}  # media_group_id -> {file_ids, caption, first_update, user_id}

    async def process_media_group_after_delay(
        group_id: str, bot, application
    ):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—Ä–∞–Ω–Ω–æ–≥–æ –∞–ª—å–±–æ–º–∞ –ø–æ—Å–ª–µ –∑–∞–¥–µ—Ä–∂–∫–∏ (–±–µ–∑ JobQueue)."""
        await asyncio.sleep(MEDIA_GROUP_DELAY)
        data = media_groups.pop(group_id, None)
        if not data:
            return

        file_ids = data["file_ids"]
        caption = data.get("caption", "")
        first_update = data["first_update"]
        user_id = data["user_id"]
        user_data = application.user_data[user_id]
        model = user_data.get("model", DEFAULT_MODEL)

        # –†–µ–∂–∏–º—ã create/dalle_create: —Ç–æ–ª—å–∫–æ caption, —Ñ–æ—Ç–æ –Ω–µ —Å–∫–∞—á–∏–≤–∞–µ–º
        if model in ("create", "dalle_create"):
            user_data["pending_images"] = []
            if caption:
                class Ctx:
                    pass
                ctx = Ctx()
                ctx.bot = bot
                ctx.application = application
                ctx.user_data = user_data
                await process_and_reply(first_update, ctx, [], caption)
            else:
                mode_name = "DALL-E Gen" if model == "dalle_create" else "Create"
                await first_update.message.reply_text(
                    f"–í —Ä–µ–∂–∏–º–µ {mode_name} –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (–ø–æ–¥–ø–∏—Å—å –∫ —Ñ–æ—Ç–æ)."
                )
            return

        logger.info(
            "–°–æ–±—Ä–∞–Ω –∞–ª—å–±–æ–º: %d —Ñ–æ—Ç–æ –æ—Ç user_id=%s",
            len(file_ids),
            user_id,
        )

        images: list[bytes] = []
        for fid in file_ids:
            f = await bot.get_file(fid)
            images.append(bytes(await f.download_as_bytearray()))

        existing = list(user_data.get("pending_images", []))
        if model == "gpt-5.2":
            images = images[:1]  # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º: —Ç–æ–ª—å–∫–æ 1 —Ñ–æ—Ç–æ
        else:
            images = existing + images

        if len(images) > 10:
            images = images[-10:]
            await first_update.message.reply_text("–ú–∞–∫—Å–∏–º—É–º 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ò—Å–ø–æ–ª—å–∑—É—é –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10.")

        class Ctx:
            pass
        ctx = Ctx()
        ctx.bot = bot
        ctx.application = application
        ctx.user_data = application.user_data[user_id]
        if caption:
            user_data["pending_images"] = []
            await process_and_reply(first_update, ctx, images, caption)
        else:
            user_data["pending_images"] = images
            model_label = MODEL_LABELS.get(model, model)
            await first_update.message.reply_text(
                f"–ü–æ–ª—É—á–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ú–æ–¥–µ–ª—å: {model_label}\n"
                "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—É—é –∫–æ–º–∞–Ω–¥—É –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –ø–æ–¥–ø–∏—Å—å."
            )

    async def handle_images(update: Update, context: ContextTypes.DEFAULT_TYPE):
        message = update.message
        user = update.effective_user
        caption = (message.caption or "").strip()

        # –†–µ–∂–∏–º—ã create/dalle_create: —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç. –û–¥–∏–Ω–æ—á–Ω–æ–µ —Ñ–æ—Ç–æ ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º caption
        if get_model(context) in ("create", "dalle_create") and not message.media_group_id:
            if caption:
                context.user_data["pending_images"] = []
                await process_and_reply(update, context, [], caption)
            else:
                mode_name = "DALL-E Gen" if get_model(context) == "dalle_create" else "Create"
                await message.reply_text(
                    f"–í —Ä–µ–∂–∏–º–µ {mode_name} –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è "
                    "(–±–µ–∑ —Ñ–æ—Ç–æ)."
                )
            return

        # –ê–ª—å–±–æ–º: –∫–∞–∂–¥–æ–µ —Ñ–æ—Ç–æ –ø—Ä–∏—Ö–æ–¥–∏—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º —Å –æ–±—â–∏–º media_group_id
        if message.media_group_id:
            file_id = None
            if message.photo:
                file_id = max(message.photo, key=lambda p: p.file_size).file_id
            elif message.document and (message.document.mime_type or "").startswith("image/"):
                file_id = message.document.file_id

            if not file_id:
                if message.document:
                    await message.reply_text("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (PNG, JPEG).")
                return

            group_id = str(message.media_group_id)
            if group_id in media_groups:
                media_groups[group_id]["file_ids"].append(file_id)
                logger.debug(
                    "–î–æ–±–∞–≤–ª–µ–Ω–æ —Ñ–æ—Ç–æ –≤ –∞–ª—å–±–æ–º %s, –≤—Å–µ–≥–æ %d",
                    group_id,
                    len(media_groups[group_id]["file_ids"]),
                )
            else:
                media_groups[group_id] = {
                    "file_ids": [file_id],
                    "caption": caption,
                    "user_id": user.id,
                    "first_update": update,
                }
                asyncio.create_task(
                    process_media_group_after_delay(
                        group_id, context.bot, context.application
                    )
                )
                logger.info("–ù–∞—á–∞—Ç —Å–±–æ—Ä –∞–ª—å–±–æ–º–∞ %s –æ—Ç user_id=%s", group_id, user.id)
            return

        # –û–¥–∏–Ω–æ—á–Ω–æ–µ —Ñ–æ—Ç–æ –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç
        images: list[bytes] = list(context.user_data.get("pending_images", []))
        if get_model(context) == "gpt-5.2":
            images = []  # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º: —Ç–æ–ª—å–∫–æ 1 –Ω–æ–≤–æ–µ —Ñ–æ—Ç–æ

        logger.info(
            "–ü–æ–ª—É—á–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç user_id=%s: photo=%s, document=%s, caption=%r",
            user.id,
            bool(message.photo),
            bool(message.document),
            caption or None,
        )

        if message.photo:
            largest = max(message.photo, key=lambda p: p.file_size)
            file = await context.bot.get_file(largest.file_id)
            images.append(bytes(await file.download_as_bytearray()))
        elif message.document:
            doc = message.document
            mime = doc.mime_type or ""
            logger.debug("–î–æ–∫—É–º–µ–Ω—Ç: file_id=%s, mime=%s", doc.file_id, mime)
            if not mime.startswith("image/"):
                logger.warning("–û—Ç–∫–ª–æ–Ω—ë–Ω –Ω–µ-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç user_id=%s: mime=%s", user.id, mime)
                await message.reply_text("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (PNG, JPEG).")
                return
            file = await context.bot.get_file(doc.file_id)
            images.append(bytes(await file.download_as_bytearray()))

        if len(images) > 10:
            logger.info("–û–±—Ä–µ–∑–∫–∞ –¥–æ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–ø–æ–ª—É—á–µ–Ω–æ %d)", len(images))
            await message.reply_text("–ú–∞–∫—Å–∏–º—É–º 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10.")
            images = images[-10:]

        if caption:
            logger.info(
                "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ user_id=%s: %d –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, prompt=%r",
                user.id,
                len(images),
                caption,
            )
            context.user_data["pending_images"] = []
            await process_and_reply(update, context, images, caption)
        else:
            context.user_data["pending_images"] = images
            logger.debug("–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ %d –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ pending –¥–ª—è user_id=%s", len(images), user.id)
            model = get_model(context)
            model_label = MODEL_LABELS.get(model, model)
            await message.reply_text(
                f"–ü–æ–ª—É—á–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ú–æ–¥–µ–ª—å: {model_label}\n"
                "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—É—é –∫–æ–º–∞–Ω–¥—É –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –ø–æ–¥–ø–∏—Å—å."
            )

    async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
        message = update.message
        user = update.effective_user
        text = (message.text or "").strip()
        images = context.user_data.get("pending_images", [])

        logger.info(
            "–¢–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç user_id=%s: %r, pending_images=%d",
            user.id,
            text[:100],
            len(images),
        )

        # –†–µ–∂–∏–º create: —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç, –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        if get_model(context) == "create":
            if not text:
                await message.reply_text("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
                return
            if len(text) > 4000:
                text = text[:4000] + "\n\n[... –æ–±—Ä–µ–∑–∞–Ω–æ]"
                await message.reply_text("–û–ø–∏—Å–∞–Ω–∏–µ –æ–±—Ä–µ–∑–∞–Ω–æ –¥–æ 4000 —Å–∏–º–≤–æ–ª–æ–≤.")
            context.user_data["pending_images"] = []
            await process_and_reply(update, context, [], text)
            return

        # –†–µ–∂–∏–º dalle_create: —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç (DALL-E 2, –ª–∏–º–∏—Ç 1000 —Å–∏–º–≤–æ–ª–æ–≤)
        if get_model(context) == "dalle_create":
            if not text:
                await message.reply_text("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
                return
            if len(text) > 1000:
                text = text[:1000] + "\n\n[... –æ–±—Ä–µ–∑–∞–Ω–æ]"
                await message.reply_text("DALL-E 2: –æ–ø–∏—Å–∞–Ω–∏–µ –æ–±—Ä–µ–∑–∞–Ω–æ –¥–æ 1000 —Å–∏–º–≤–æ–ª–æ–≤.")
            context.user_data["pending_images"] = []
            await process_and_reply(update, context, [], text)
            return

        # –†–µ–∂–∏–º text (gpt-5.2): –º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –ò–õ–ò —Ç–µ–∫—Å—Ç + 1 —Ñ–æ—Ç–æ
        if get_model(context) == "gpt-5.2":
            if not text:
                await message.reply_text("–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ —Å –ø–æ–¥–ø–∏—Å—å—é.")
                return
            if len(text) > 4000:
                text = text[:4000] + "\n\n[... –æ–±—Ä–µ–∑–∞–Ω–æ]"
                await message.reply_text("–ü—Ä–æ–º–ø—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–æ 4000 —Å–∏–º–≤–æ–ª–æ–≤.")
            context.user_data["pending_images"] = []
            await process_and_reply(update, context, images, text)
            return

        if not images:
            logger.debug("user_id=%s: –Ω–µ—Ç –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", user.id)
            await message.reply_text(
                "–°–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∑–∞—Ç–µ–º –∫–æ–º–∞–Ω–¥—É —Ç–µ–∫—Å—Ç–æ–º."
            )
            return

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å API
        if len(text) > 4000:
            text = text[:4000] + "\n\n[... –æ–±—Ä–µ–∑–∞–Ω–æ]"
            await message.reply_text("–ü—Ä–æ–º–ø—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–æ 4000 —Å–∏–º–≤–æ–ª–æ–≤.")

        context.user_data["pending_images"] = []
        await process_and_reply(update, context, images, text)

    def chunk_text(text: str, max_len: int = TELEGRAM_MAX_MESSAGE) -> list[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ –Ω–µ –±–æ–ª–µ–µ max_len —Å–∏–º–≤–æ–ª–æ–≤."""
        if len(text) <= max_len:
            return [text] if text else []
        chunks = []
        while text:
            chunk = text[:max_len]
            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–±–∏—Ç—å –ø–æ –ø–µ—Ä–µ–Ω–æ—Å—É —Å—Ç—Ä–æ–∫–∏
            last_nl = chunk.rfind("\n")
            if last_nl > max_len // 2:
                chunk = text[: last_nl + 1]
            chunks.append(chunk)
            text = text[len(chunk) :]
        return chunks

    async def process_and_reply(
        update: Update,
        context: ContextTypes.DEFAULT_TYPE,
        images: list,
        prompt: str,
    ):
        user = update.effective_user
        model = get_model(context)
        logger.info(
            "–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è user_id=%s: %d –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, model=%s, prompt=%r",
            user.id,
            len(images),
            model,
            prompt,
        )

        # –†–µ–∂–∏–º create: —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç ‚Üí –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (images.generate, gpt-image-1.5)
        if model == "create":
            model_label = MODEL_LABELS.get(model, model)
            message = await update.message.reply_text(
                f"–ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ({model_label})‚Ä¶"
            )
            try:
                result_bytes, usage_str = await asyncio.to_thread(
                    processor.process_create,
                    prompt,
                    model="gpt-image-1.5",
                )
            except ValueError as e:
                await message.edit_text(str(e))
                return
            except Exception as e:
                err_msg = _format_image_error(e)
                if "moderation_blocked" in str(e):
                    logger.info("Create: moderation blocked –¥–ª—è user_id=%s", user.id)
                else:
                    logger.exception(
                        "–û—à–∏–±–∫–∞ create –¥–ª—è user_id=%s: %s",
                        user.id,
                        e,
                    )
                await message.edit_text(err_msg)
                return
            output = Path("temp_output.png")
            output.write_bytes(result_bytes)
            caption = f"–ú–æ–¥–µ–ª—å: {model_label}"
            if usage_str:
                caption += f"\n{usage_str}"
            try:
                await update.message.reply_photo(
                    photo=output.open("rb"),
                    caption=caption,
                )
            finally:
                output.unlink(missing_ok=True)
            await message.delete()
            return

        # –†–µ–∂–∏–º dalle_create: —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç ‚Üí –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (images.generate, DALL-E 2)
        if model == "dalle_create":
            model_label = MODEL_LABELS.get(model, model)
            message = await update.message.reply_text(
                f"–ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ({model_label})‚Ä¶"
            )
            try:
                result_bytes, usage_str = await asyncio.to_thread(
                    processor.process_create,
                    prompt,
                    model="dall-e-2",
                )
            except ValueError as e:
                await message.edit_text(str(e))
                return
            except Exception as e:
                err_msg = _format_image_error(e)
                if "moderation_blocked" in str(e):
                    logger.info("DALL-E create: moderation blocked –¥–ª—è user_id=%s", user.id)
                else:
                    logger.exception(
                        "–û—à–∏–±–∫–∞ dalle_create –¥–ª—è user_id=%s: %s",
                        user.id,
                        e,
                    )
                await message.edit_text(err_msg)
                return
            output = Path("temp_output.png")
            output.write_bytes(result_bytes)
            caption = f"–ú–æ–¥–µ–ª—å: {model_label}"
            if usage_str:
                caption += f"\n{usage_str}"
            try:
                await update.message.reply_photo(
                    photo=output.open("rb"),
                    caption=caption,
                )
            finally:
                output.unlink(missing_ok=True)
            await message.delete()
            return

        # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º (gpt-5.2): —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –ò–õ–ò 1 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ + —Ç–µ–∫—Å—Ç
        if model == "gpt-5.2":
            message = await update.message.reply_text("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é‚Ä¶")
            try:
                if images:
                    if len(images) > 1:
                        images = images[:1]
                        logger.info("–¢–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º: –±–µ—Ä—ë–º 1 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
                    result_text = await asyncio.to_thread(
                        processor.process_text_with_image,
                        images[0],
                        prompt,
                        model=model,
                    )
                else:
                    result_text = await asyncio.to_thread(
                        processor.process_text_only,
                        prompt,
                        model=model,
                    )
            except (ValueError, IndexError) as e:
                await message.edit_text(str(e))
                return
            except Exception as e:
                logger.exception("–û—à–∏–±–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞ –¥–ª—è user_id=%s: %s", user.id, e)
                await message.edit_text(f"–û—à–∏–±–∫–∞: {e}")
                return

            await message.delete()
            parts = chunk_text(result_text)
            if not parts:
                await update.message.reply_text("(–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç)")
            else:
                for part in parts:
                    await update.message.reply_text(part)
            return

        # –†–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        model_label = MODEL_LABELS.get(model, model)
        message = await update.message.reply_text(
            f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ({model_label})‚Ä¶"
        )
        try:
            result_bytes, usage_str = await asyncio.to_thread(
                processor.process,
                images,
                prompt,
                model=model,
            )
        except ValueError as e:
            logger.warning("–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è user_id=%s: %s", user.id, e)
            await message.edit_text(str(e))
            return
        except Exception as e:
            err_msg = _format_image_error(e)
            if "moderation_blocked" in str(e):
                logger.info("–û–±—Ä–∞–±–æ—Ç–∫–∞: moderation blocked –¥–ª—è user_id=%s", user.id)
            else:
                logger.exception(
                    "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–ª—è user_id=%s: %s",
                    user.id,
                    e,
                )
            await message.edit_text(err_msg)
            return

        logger.info(
            "–£—Å–ø–µ—à–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è user_id=%s: —Ä–µ–∑—É–ª—å—Ç–∞—Ç %d –±–∞–π—Ç",
            user.id,
            len(result_bytes),
        )

        output = Path("temp_output.png")
        output.write_bytes(result_bytes)
        caption = f"–ú–æ–¥–µ–ª—å: {model_label}"
        if usage_str:
            caption += f"\n{usage_str}"
        try:
            await update.message.reply_photo(
                photo=output.open("rb"),
                caption=caption,
            )
            logger.debug("–§–æ—Ç–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ user_id=%s", user.id)
        finally:
            output.unlink(missing_ok=True)
        await message.delete()

    def main():
        persistence_path = os.environ.get("BOT_DATA_PATH", "bot_data.pickle")
        persistence = PicklePersistence(persistence_path)
        app = Application.builder().token(token).persistence(persistence).build()
        app.add_handler(CommandHandler("start", start))
        app.add_handler(CommandHandler("text", cmd_text))
        app.add_handler(CommandHandler("image1", cmd_image1))
        app.add_handler(CommandHandler("image15", cmd_image15))
        app.add_handler(CommandHandler("dalle", cmd_dalle))
        app.add_handler(CommandHandler("create", cmd_create))
        app.add_handler(CommandHandler("dalle_gen", cmd_dalle_gen))
        app.add_handler(CommandHandler("help", cmd_help))
        app.add_handler(MessageHandler(filters.PHOTO, handle_images))
        app.add_handler(MessageHandler(filters.Document.IMAGE, handle_images))
        app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

        logger.info("Telegram-–±–æ—Ç –∑–∞–ø—É—â–µ–Ω, –æ–∂–∏–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        app.run_polling(allowed_updates=Update.ALL_TYPES)
        logger.info("Telegram-–±–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

    main()


def run_cli():
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π CLI-—Ä–µ–∂–∏–º."""
    logger.info("–ó–∞–ø—É—Å–∫ CLI-—Ä–µ–∂–∏–º–∞")

    processor = ImageProcessor()

    print("ImageBot ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ OpenAI\n")
    print("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç–∏ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º (1-10 —à—Ç.), —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª:")
    paths_str = input("> ").strip()
    paths = [Path(p.strip()) for p in paths_str.split() if p.strip()]

    if not paths:
        print("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω—ã.")
        return

    for p in paths:
        if not p.exists():
            logger.error("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: %s", p)
            print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {p}")
            return

    logger.info("CLI: –≤–≤–µ–¥–µ–Ω–æ %d –ø—É—Ç–µ–π: %s", len(paths), paths)

    print("\n–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—É—é –∫–æ–º–∞–Ω–¥—É:")
    prompt = input("> ").strip()
    if not prompt:
        print("–ö–æ–º–∞–Ω–¥–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ–π.")
        return

    logger.info("CLI: –æ–±—Ä–∞–±–æ—Ç–∫–∞ %d –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å prompt=%r", len(paths), prompt)
    print("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é‚Ä¶")
    try:
        result_bytes, usage_str = processor.process(paths, prompt)
    except Exception as e:
        logger.exception("CLI: –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: %s", e)
        print(f"–û—à–∏–±–∫–∞: {e}")
        return

    output_path = Path("output.png")
    output_path.write_bytes(result_bytes)
    logger.info("CLI: —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ %s (%d –±–∞–π—Ç)", output_path, len(result_bytes))
    print(f"–ì–æ—Ç–æ–≤–æ. –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_path.absolute()}")
    if usage_str:
        print(usage_str)


if __name__ == "__main__":
    mode = (sys.argv[1] if len(sys.argv) > 1 else "").lower()
    if mode == "cli":
        run_cli()
    elif mode == "telegram" or mode == "tg":
        run_telegram_bot()
    else:
        print("ImageBot")
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("  python bot.py telegram    ‚Äî –∑–∞–ø—É—Å–∫ Telegram-–±–æ—Ç–∞")
        print("  python bot.py cli         ‚Äî –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º –≤ –∫–æ–Ω—Å–æ–ª–∏")
        print("  python bot.py telegram -v ‚Äî —Å –≤—ã–≤–æ–¥–æ–º –ª–æ–≥–æ–≤ –≤ –∫–æ–Ω—Å–æ–ª—å (--log)")
        print()
        print("–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ª–æ–≥–∏ –≤ –∫–æ–Ω—Å–æ–ª—å –æ—Ç–∫–ª—é—á–µ–Ω—ã (–¥–ª—è —Ä–∞–±–æ—Ç—ã –∫–∞–∫ —Å–µ—Ä–≤–∏—Å).")
        print("–§–ª–∞–≥ --log –∏–ª–∏ -v –≤–∫–ª—é—á–∞–µ—Ç –≤—ã–≤–æ–¥ –ª–æ–≥–æ–≤.")
        print()
        print("–ù–∞—Å—Ç—Ä–æ–π—Ç–µ .env (—Å–∫–æ–ø–∏—Ä—É–π—Ç–µ .env.example):")
        print("  OPENAI_API_KEY ‚Äî –∫–ª—é—á OpenAI")
        print("  TELEGRAM_BOT_TOKEN ‚Äî —Ç–æ–∫–µ–Ω –±–æ—Ç–∞ (–¥–ª—è Telegram)")
